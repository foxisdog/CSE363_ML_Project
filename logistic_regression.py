# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KAqaoDOeMq7oMfPlCuaU3xgtIjBu0tNt
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import (
    precision_score, recall_score, accuracy_score,
    roc_curve, roc_auc_score, log_loss
)

# ============================================================
# 1. 데이터 로드
# ============================================================
csv_path = "./Dry_Eye_Dataset_preprocessed.csv"
df = pd.read_csv(csv_path)

target_col = "Dry Eye Disease"
X = df.drop(columns=[target_col]).values
y = df[target_col].values

# ============================================================
# 2. Test set 분리 (15%)
# ============================================================
X_train_full, X_test, y_train_full, y_test = train_test_split(
    X, y,
    test_size=0.15,
    random_state=42,
    stratify=y
)

print("Train+Val size:", X_train_full.shape[0])
print("Test size     :", X_test.shape[0])

# ============================================================
# 3. K-Fold 설정
# ============================================================
k = 5
skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)

n_epochs = 100

all_train_losses = []
all_val_losses = []

# ============================================================
# 4. K-Fold 학습
# ============================================================
for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_full, y_train_full), 1):
    print(f"\n====== Fold {fold} ======")

    X_train = X_train_full[train_idx]
    X_val   = X_train_full[val_idx]
    y_train = y_train_full[train_idx]
    y_val   = y_train_full[val_idx]

    # 표준화
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_val   = scaler.transform(X_val)

    model = SGDClassifier(
        loss="log_loss",
        penalty="l2",
        alpha=1e-4,
        learning_rate="optimal",
        max_iter=1,
        random_state=42
    )

    classes = np.unique(y_train)

    train_losses = []
    val_losses = []

    for epoch in range(1, n_epochs + 1):
        if epoch == 1:
            model.partial_fit(X_train, y_train, classes=classes)
        else:
            model.partial_fit(X_train, y_train)

        train_proba = model.predict_proba(X_train)
        val_proba   = model.predict_proba(X_val)

        train_loss = log_loss(y_train, train_proba)
        val_loss   = log_loss(y_val, val_proba)

        train_losses.append(train_loss)
        val_losses.append(val_loss)

    all_train_losses.append(train_losses)
    all_val_losses.append(val_losses)

# ============================================================
# 5. Fold 평균 Loss 계산
# ============================================================
mean_train_loss = np.mean(all_train_losses, axis=0)
mean_val_loss   = np.mean(all_val_losses, axis=0)

# ============================================================
# 6. Test Set 최종 평가 (모든 train 데이터로 재학습)
# ============================================================
scaler = StandardScaler()
X_train_full = scaler.fit_transform(X_train_full)
X_test = scaler.transform(X_test)

final_model = SGDClassifier(
    loss="log_loss",
    penalty="l2",
    alpha=1e-4,
    learning_rate="optimal",
    max_iter=1000,
    random_state=42
)
final_model.fit(X_train_full, y_train_full)

y_test_proba = final_model.predict_proba(X_test)[:, 1]
y_test_pred  = final_model.predict(X_test)

accuracy  = accuracy_score(y_test, y_test_pred)
precision = precision_score(y_test, y_test_pred)
recall    = recall_score(y_test, y_test_pred)
auc       = roc_auc_score(y_test, y_test_proba)

fpr, tpr, _ = roc_curve(y_test, y_test_proba)

print("\n===== Final Test Performance =====")
print(f"Accuracy : {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall   : {recall:.4f}")
print(f"AUC      : {auc:.4f}")

# ============================================================
# 7. 시각화
# ============================================================

# K-Fold 평균 Loss 그래프
plt.figure(figsize=(6,4))
plt.plot(mean_train_loss, label="Mean Train Loss")
plt.plot(mean_val_loss, label="Mean Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Log Loss")
plt.title(f"{k}-Fold Average Loss Curve")
plt.legend()
plt.grid(True)
plt.show()

# ROC Curve
plt.figure(figsize=(6,4))
plt.plot(fpr, tpr, label=f"ROC (AUC = {auc:.3f})")
plt.plot([0,1],[0,1],'--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Test Set")
plt.legend()
plt.grid(True)
plt.show()

