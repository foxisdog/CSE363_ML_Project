{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNgT1SNIs6Qr6/EDWSD8vYs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import shap\n","import warnings\n","import time\n","\n","# 모델 평가 및 분리\n","from sklearn.model_selection import cross_val_score, train_test_split\n","\n","# Tree-based Models (Scikit-learn: CPU Multi-core)\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import (\n","    RandomForestClassifier,\n","    AdaBoostClassifier,\n","    GradientBoostingClassifier,\n","    BaggingClassifier,\n","    ExtraTreesClassifier\n",")\n","\n","# 외부 라이브러리 모델\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","\n","# 경고 메시지 무시\n","warnings.filterwarnings('ignore')\n","\n","# --------------------------------------------------------------------------------\n","# 1. 데이터 로드 및 전처리\n","# --------------------------------------------------------------------------------\n","df = pd.read_csv('Dry_Eye_Dataset_preprocessed.csv')\n","\n","target_col = 'Dry Eye Disease'\n","X = df.drop(columns=[target_col])\n","y = df[target_col]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# --------------------------------------------------------------------------------\n","# 2. Feature Importance 계산 (SHAP 방식 + XGBoost GPU)\n","# --------------------------------------------------------------------------------\n","print(\"Calculating Feature Importance using SHAP with XGBoost...\")\n","\n","# [수정됨] 최신 XGBoost 문법 적용 (안전한 설정)\n","# GPU가 있으면 쓰고, 없으면 알아서 CPU로 돕니다.\n","xgb_for_shap = XGBClassifier(\n","    random_state=42,\n","    tree_method='hist',       # 최신 버전 표준 (빠름)\n","    device='cuda',            # GPU 사용 (T4 감지)\n","    eval_metric='logloss',\n","    use_label_encoder=False,\n","    verbosity=0\n",")\n","\n","# 학습 시도 (GPU 에러 발생 시 CPU로 자동 전환하도록 try-except 처리 안함, 최신버전은 device='cuda'로 해결됨)\n","try:\n","    xgb_for_shap.fit(X_train, y_train)\n","except Exception as e:\n","    print(f\"GPU Init failed, falling back to CPU: {e}\")\n","    xgb_for_shap = XGBClassifier(random_state=42, n_jobs=-1)\n","    xgb_for_shap.fit(X_train, y_train)\n","\n","# SHAP 계산\n","explainer = shap.TreeExplainer(xgb_for_shap)\n","shap_values = explainer.shap_values(X_test)\n","\n","# SHAP 값 처리\n","if isinstance(shap_values, list):\n","    feature_importance_vals = np.abs(shap_values[1]).mean(axis=0)\n","else:\n","    feature_importance_vals = np.abs(shap_values).mean(axis=0)\n","\n","feature_names = X_train.columns\n","feature_importance_list = sorted(zip(feature_importance_vals, feature_names), reverse=True)\n","\n","# --------------------------------------------------------------------------------\n","# 3. 정렬된 Feature 목록 출력\n","# --------------------------------------------------------------------------------\n","print(\"\\n[Feature Importance Ranking (SHAP via XGBoost)]\")\n","print(f\"{'Rank':<5} | {'Feature Name':<30} | {'SHAP Importance':<15}\")\n","print(\"-\" * 60)\n","\n","for idx, (score, name) in enumerate(feature_importance_list):\n","    print(f\"{idx + 1:<5} | {name:<30} | {score:.5f}\")\n","\n","sorted_features = [name for score, name in feature_importance_list]\n","\n","print(\"\\n\" + \"=\"*85 + \"\\n\")\n","\n","# --------------------------------------------------------------------------------\n","# 4. 모델별 Top 1 ~ 10 성능 평가\n","# --------------------------------------------------------------------------------\n","\n","models = [\n","    # 1. Scikit-learn Models (CPU n_jobs=-1)\n","    (\"Decision Tree\", DecisionTreeClassifier(random_state=42)),\n","    (\"Random Forest\", RandomForestClassifier(random_state=42, n_jobs=-1)),\n","    (\"AdaBoost\", AdaBoostClassifier(random_state=42)),\n","    (\"Gradient Boosting\", GradientBoostingClassifier(random_state=42)),\n","    (\"Bagging\", BaggingClassifier(random_state=42, n_jobs=-1)),\n","    (\"Extra Trees\", ExtraTreesClassifier(random_state=42, n_jobs=-1)),\n","\n","    # 2. XGBoost (GPU Accelerated - Safe Mode)\n","    (\"XGBoost\", XGBClassifier(\n","        random_state=42,\n","        tree_method='hist',   # 'gpu_hist' 대신 'hist' 사용\n","        device='cuda',        # GPU 명시\n","        eval_metric='logloss',\n","        use_label_encoder=False,\n","        verbosity=0\n","    )),\n","\n","    # 3. LightGBM (CPU Multi-core - Safe Mode)\n","    # Colab에서 LightGBM GPU는 별도 컴파일 없이는 에러가 잘 나므로 CPU 멀티코어가 가장 안전하고 빠름\n","    (\"LightGBM\", LGBMClassifier(\n","        random_state=42,\n","        verbose=-1,\n","        n_jobs=-1\n","    ))\n","]\n","\n","print(f\"{'Model':<20} | {'N_Feats':<8} | {'CV_Valid_Acc':<12} | {'Test_Acc':<10} | {'Note'}\")\n","print(\"-\" * 85)\n","\n","for model_name, model in models:\n","    max_k = min(10, len(sorted_features))\n","\n","    for k in range(1, max_k + 1):\n","        current_features = sorted_features[:k]\n","\n","        X_train_sel = X_train[current_features]\n","        X_test_sel = X_test[current_features]\n","\n","        try:\n","            # XGBoost/LGBM 자체 GPU/CPU 설정 따름.\n","            # Scikit-learn CV 함수에게는 병렬처리를 맡기지 않음 (n_jobs=1) -> 모델 내부에서 병렬처리 하도록 유도\n","            # (모델 내부 n_jobs=-1과 CV n_jobs=-1이 충돌하면 오히려 느려질 수 있어서, 모델 위주로 둠)\n","            if \"XGBoost\" in model_name or \"LightGBM\" in model_name or \"Random Forest\" in model_name or \"Extra Trees\" in model_name:\n","                 cv_n_jobs = 1 # 모델 안에서 병렬처리\n","            else:\n","                 cv_n_jobs = -1 # 모델이 병렬처리 없으면 CV에서 병렬처리\n","\n","            cv_scores = cross_val_score(model, X_train_sel, y_train, cv=5, scoring='accuracy', n_jobs=cv_n_jobs)\n","            cv_acc = cv_scores.mean()\n","\n","            # 모델 학습 및 테스트\n","            model.fit(X_train_sel, y_train)\n","            test_acc = model.score(X_test_sel, y_test)\n","\n","            print(f\"{model_name:<20} | {k:<8} | {cv_acc:.4f}       | {test_acc:.4f}     | Top {k} features\")\n","\n","        except Exception as e:\n","            print(f\"{model_name:<20} | {k:<8} | Error          | Error          | {e}\")\n","\n","    print(\"-\" * 85)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ZQiBLpWgOa8","executionInfo":{"status":"ok","timestamp":1764502187926,"user_tz":-540,"elapsed":212644,"user":{"displayName":"성지양","userId":"15077248708045203212"}},"outputId":"cc8c057c-e5db-4e88-ec49-73fc4076f630"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Calculating Feature Importance using SHAP with XGBoost...\n","\n","[Feature Importance Ranking (SHAP via XGBoost)]\n","Rank  | Feature Name                   | SHAP Importance\n","------------------------------------------------------------\n","1     | Discomfort Eye-strain          | 0.26283\n","2     | Itchiness/Irritation in eye    | 0.25358\n","3     | Redness in eye                 | 0.25239\n","4     | Average screen time            | 0.14805\n","5     | Physical activity              | 0.13879\n","6     | Systolic_BP                    | 0.13239\n","7     | Weight                         | 0.11887\n","8     | Sleep duration                 | 0.11734\n","9     | Daily steps                    | 0.11470\n","10    | Height                         | 0.11149\n","11    | Age                            | 0.11047\n","12    | Diastolic_BP                   | 0.10836\n","13    | Heart rate                     | 0.10554\n","14    | Sleep quality                  | 0.06508\n","15    | Stress level                   | 0.06117\n","16    | Smart device before bed        | 0.05811\n","17    | Gender                         | 0.04919\n","18    | Alcohol consumption            | 0.03720\n","19    | Smoking                        | 0.03576\n","20    | Feel sleepy during day         | 0.03215\n","21    | Blue-light filter              | 0.03186\n","22    | Wake up during night           | 0.03182\n","23    | Ongoing medication             | 0.03014\n","24    | Caffeine consumption           | 0.02656\n","25    | Sleep disorder                 | 0.02540\n","26    | Medical issue                  | 0.02455\n","\n","=====================================================================================\n","\n","Model                | N_Feats  | CV_Valid_Acc | Test_Acc   | Note\n","-------------------------------------------------------------------------------------\n","Decision Tree        | 1        | 0.6465       | 0.6733     | Top 1 features\n","Decision Tree        | 2        | 0.6480       | 0.6498     | Top 2 features\n","Decision Tree        | 3        | 0.6971       | 0.7017     | Top 3 features\n","Decision Tree        | 4        | 0.6743       | 0.6837     | Top 4 features\n","Decision Tree        | 5        | 0.5754       | 0.5763     | Top 5 features\n","Decision Tree        | 6        | 0.5724       | 0.5630     | Top 6 features\n","Decision Tree        | 7        | 0.5668       | 0.5745     | Top 7 features\n","Decision Tree        | 8        | 0.5667       | 0.5620     | Top 8 features\n","Decision Tree        | 9        | 0.5658       | 0.5767     | Top 9 features\n","Decision Tree        | 10       | 0.5633       | 0.5797     | Top 10 features\n","-------------------------------------------------------------------------------------\n","Random Forest        | 1        | 0.6465       | 0.6733     | Top 1 features\n","Random Forest        | 2        | 0.6467       | 0.6498     | Top 2 features\n","Random Forest        | 3        | 0.6971       | 0.7017     | Top 3 features\n","Random Forest        | 4        | 0.6781       | 0.6840     | Top 4 features\n","Random Forest        | 5        | 0.6185       | 0.6188     | Top 5 features\n","Random Forest        | 6        | 0.6427       | 0.6567     | Top 6 features\n","Random Forest        | 7        | 0.6684       | 0.6847     | Top 7 features\n","Random Forest        | 8        | 0.6804       | 0.6863     | Top 8 features\n","Random Forest        | 9        | 0.6825       | 0.6880     | Top 9 features\n","Random Forest        | 10       | 0.6872       | 0.6913     | Top 10 features\n","-------------------------------------------------------------------------------------\n","AdaBoost             | 1        | 0.6465       | 0.6733     | Top 1 features\n","AdaBoost             | 2        | 0.6465       | 0.6733     | Top 2 features\n","AdaBoost             | 3        | 0.6971       | 0.7017     | Top 3 features\n","AdaBoost             | 4        | 0.6937       | 0.7037     | Top 4 features\n","AdaBoost             | 5        | 0.6893       | 0.7035     | Top 5 features\n","AdaBoost             | 6        | 0.6869       | 0.7017     | Top 6 features\n","AdaBoost             | 7        | 0.6866       | 0.7017     | Top 7 features\n","AdaBoost             | 8        | 0.6857       | 0.7017     | Top 8 features\n","AdaBoost             | 9        | 0.6854       | 0.6977     | Top 9 features\n","AdaBoost             | 10       | 0.6826       | 0.6953     | Top 10 features\n","-------------------------------------------------------------------------------------\n","Gradient Boosting    | 1        | 0.6465       | 0.6733     | Top 1 features\n","Gradient Boosting    | 2        | 0.6480       | 0.6498     | Top 2 features\n","Gradient Boosting    | 3        | 0.6971       | 0.7017     | Top 3 features\n","Gradient Boosting    | 4        | 0.6971       | 0.7017     | Top 4 features\n","Gradient Boosting    | 5        | 0.6966       | 0.7007     | Top 5 features\n","Gradient Boosting    | 6        | 0.6965       | 0.7010     | Top 6 features\n","Gradient Boosting    | 7        | 0.6964       | 0.7013     | Top 7 features\n","Gradient Boosting    | 8        | 0.6968       | 0.7013     | Top 8 features\n","Gradient Boosting    | 9        | 0.6972       | 0.7015     | Top 9 features\n","Gradient Boosting    | 10       | 0.6973       | 0.7015     | Top 10 features\n","-------------------------------------------------------------------------------------\n","Bagging              | 1        | 0.6465       | 0.6733     | Top 1 features\n","Bagging              | 2        | 0.6467       | 0.6498     | Top 2 features\n","Bagging              | 3        | 0.6971       | 0.7017     | Top 3 features\n","Bagging              | 4        | 0.6733       | 0.6883     | Top 4 features\n","Bagging              | 5        | 0.5969       | 0.5917     | Top 5 features\n","Bagging              | 6        | 0.6051       | 0.6032     | Top 6 features\n","Bagging              | 7        | 0.6140       | 0.6140     | Top 7 features\n","Bagging              | 8        | 0.6109       | 0.6230     | Top 8 features\n","Bagging              | 9        | 0.6138       | 0.6325     | Top 9 features\n","Bagging              | 10       | 0.6078       | 0.6085     | Top 10 features\n","-------------------------------------------------------------------------------------\n","Extra Trees          | 1        | 0.6465       | 0.6733     | Top 1 features\n","Extra Trees          | 2        | 0.6480       | 0.6498     | Top 2 features\n","Extra Trees          | 3        | 0.6971       | 0.7017     | Top 3 features\n","Extra Trees          | 4        | 0.6743       | 0.6837     | Top 4 features\n","Extra Trees          | 5        | 0.6126       | 0.6050     | Top 5 features\n","Extra Trees          | 6        | 0.6361       | 0.6492     | Top 6 features\n","Extra Trees          | 7        | 0.6612       | 0.6770     | Top 7 features\n","Extra Trees          | 8        | 0.6771       | 0.6867     | Top 8 features\n","Extra Trees          | 9        | 0.6787       | 0.6850     | Top 9 features\n","Extra Trees          | 10       | 0.6840       | 0.6883     | Top 10 features\n","-------------------------------------------------------------------------------------\n","XGBoost              | 1        | 0.6465       | 0.6733     | Top 1 features\n","XGBoost              | 2        | 0.6480       | 0.6498     | Top 2 features\n","XGBoost              | 3        | 0.6971       | 0.7017     | Top 3 features\n","XGBoost              | 4        | 0.6836       | 0.6913     | Top 4 features\n","XGBoost              | 5        | 0.6686       | 0.6720     | Top 5 features\n","XGBoost              | 6        | 0.6617       | 0.6707     | Top 6 features\n","XGBoost              | 7        | 0.6564       | 0.6700     | Top 7 features\n","XGBoost              | 8        | 0.6523       | 0.6620     | Top 8 features\n","XGBoost              | 9        | 0.6539       | 0.6630     | Top 9 features\n","XGBoost              | 10       | 0.6527       | 0.6615     | Top 10 features\n","-------------------------------------------------------------------------------------\n","LightGBM             | 1        | 0.6465       | 0.6733     | Top 1 features\n","LightGBM             | 2        | 0.6480       | 0.6498     | Top 2 features\n","LightGBM             | 3        | 0.6971       | 0.7017     | Top 3 features\n","LightGBM             | 4        | 0.6955       | 0.7013     | Top 4 features\n","LightGBM             | 5        | 0.6919       | 0.6987     | Top 5 features\n","LightGBM             | 6        | 0.6936       | 0.6997     | Top 6 features\n","LightGBM             | 7        | 0.6924       | 0.6983     | Top 7 features\n","LightGBM             | 8        | 0.6931       | 0.6995     | Top 8 features\n","LightGBM             | 9        | 0.6923       | 0.6980     | Top 9 features\n","LightGBM             | 10       | 0.6920       | 0.6990     | Top 10 features\n","-------------------------------------------------------------------------------------\n"]}]}]}